{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077fbae4-94f9-4130-bfdf-8e40b12840ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.2499 - loss: 2.2168 - val_accuracy: 0.2412 - val_loss: 1.8150\n",
      "Epoch 2/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.2692 - loss: 1.7704 - val_accuracy: 0.2412 - val_loss: 1.7465\n",
      "Epoch 3/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.3522 - loss: 1.6956 - val_accuracy: 0.3529 - val_loss: 1.7603\n",
      "Epoch 4/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - accuracy: 0.4214 - loss: 1.5881 - val_accuracy: 0.3824 - val_loss: 1.6570\n",
      "Epoch 5/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - accuracy: 0.4678 - loss: 1.5316 - val_accuracy: 0.4588 - val_loss: 1.6295\n",
      "Epoch 6/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.5261 - loss: 1.4092 - val_accuracy: 0.4588 - val_loss: 1.5791\n",
      "Epoch 7/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.5762 - loss: 1.3471 - val_accuracy: 0.4118 - val_loss: 1.6629\n",
      "Epoch 8/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.5890 - loss: 1.2974 - val_accuracy: 0.5000 - val_loss: 1.5832\n",
      "Epoch 9/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 84ms/step - accuracy: 0.6209 - loss: 1.2622 - val_accuracy: 0.4294 - val_loss: 1.6432\n",
      "Epoch 10/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 79ms/step - accuracy: 0.6334 - loss: 1.2128 - val_accuracy: 0.5118 - val_loss: 1.6242\n",
      "Epoch 11/30\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 82ms/step - accuracy: 0.6636 - loss: 1.1571 - val_accuracy: 0.4882 - val_loss: 1.6135\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.4652 - loss: 1.5608\n",
      "Model accuracy on validation set: 0.46\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your STFT and labels data\n",
    "X_stft = np.load('X_stft_181.npy')\n",
    "y_labels = np.load('bd1.npy')\n",
    "\n",
    "# Adjust labels to start from 0\n",
    "y_labels -= y_labels.min()\n",
    "\n",
    "# Verify the unique labels after adjustment\n",
    "unique_labels = np.unique(y_labels)\n",
    "output_classes = len(unique_labels)\n",
    "\n",
    "# Split the STFT data into real and imaginary parts\n",
    "X_stft_real = X_stft.real\n",
    "X_stft_imag = X_stft.imag\n",
    "X_stft_combined = np.stack((X_stft_real, X_stft_imag), axis=-1)  # Shape: (850, 257, 25, 2)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_stft_combined, y_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function for basic manual data augmentation\n",
    "def augment_data(X, y):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    for i in range(len(X)):\n",
    "        # Original\n",
    "        X_augmented.append(X[i])\n",
    "        y_augmented.append(y[i])\n",
    "        \n",
    "        # Time Shift\n",
    "        shifted = np.roll(X[i], shift=np.random.randint(1, 5), axis=1)\n",
    "        X_augmented.append(shifted)\n",
    "        y_augmented.append(y[i])\n",
    "        \n",
    "        # Frequency Shift\n",
    "        shifted = np.roll(X[i], shift=np.random.randint(1, 5), axis=0)\n",
    "        X_augmented.append(shifted)\n",
    "        y_augmented.append(y[i])\n",
    "        \n",
    "    return np.array(X_augmented), np.array(y_augmented)\n",
    "\n",
    "# Apply augmentation to the training data\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
    "\n",
    "# Define a simpler CVNN model with fewer layers and increased regularization\n",
    "def create_cvnn(input_shape, output_classes):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # First and only convolutional layer\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(layers.Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(output_classes, activation=\"softmax\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the model\n",
    "input_shape = X_train.shape[1:]  # (257, 25, 2)\n",
    "cvnn_model = create_cvnn(input_shape, output_classes)\n",
    "cvnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                   loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "cvnn_model.fit(X_train_augmented, y_train_augmented, epochs=30, batch_size=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cvnn_model.evaluate(X_val, y_val)\n",
    "print(f\"Model accuracy on validation set: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ab1d5-1c39-4fb0-8b39-4a28f92f4a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
